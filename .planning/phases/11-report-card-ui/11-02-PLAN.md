---
phase: 11-report-card-ui
plan: 02
type: execute
wave: 2
depends_on: ["11-01"]
files_modified:
  - scrapegrape/publishers/tests/test_integration.py
autonomous: true

must_haves:
  truths:
    - "Submitting a URL via POST /submit creates a job, pipeline executes all steps, and the completed job page returns 200 with populated result fields"
    - "Integration test verifies the full chain: submit -> redirect -> job created -> pipeline runs -> results stored -> job page renderable"
  artifacts:
    - path: "scrapegrape/publishers/tests/test_integration.py"
      provides: "End-to-end integration test for full pipeline"
      contains: "TestFullPipelineIntegration"
  key_links:
    - from: "scrapegrape/publishers/tests/test_integration.py"
      to: "scrapegrape/publishers/views.py"
      via: "Django test client POST /submit and GET /jobs/{id}"
      pattern: "client\\.post.*submit"
    - from: "scrapegrape/publishers/tests/test_integration.py"
      to: "scrapegrape/publishers/pipeline/supervisor.py"
      via: "monkeypatch run_pipeline.delay to run synchronously with mock results"
      pattern: "monkeypatch.*run_pipeline"
---

<objective>
Write a comprehensive end-to-end integration test that verifies the full pipeline flow: URL submission creates a job, pipeline executes all steps (mocked), and the completed job page returns 200 with all result fields populated.

Purpose: TEST-04 requirement -- prove the entire system works from user input to rendered output. This is the final verification that v2.0 is complete.
Output: Integration test file that exercises the full chain with mocked pipeline steps.
</objective>

<execution_context>
@/Users/matt/.claude/get-shit-done/workflows/execute-plan.md
@/Users/matt/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/11-report-card-ui/11-RESEARCH.md
@scrapegrape/publishers/views.py
@scrapegrape/publishers/tests/test_views.py
@scrapegrape/publishers/tests/test_pipeline.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: End-to-end integration test for full pipeline flow</name>
  <files>
    scrapegrape/publishers/tests/test_integration.py
  </files>
  <action>
    Create `test_integration.py` with a `TestFullPipelineIntegration` class containing these tests:

    **Test 1: `test_submit_url_pipeline_completes_results_retrievable`**
    The primary TEST-04 test. Steps:
    1. Monkeypatch `publishers.views.run_pipeline.delay` to call a synchronous mock that:
       - Gets the ResolutionJob by ID
       - Creates a Publisher with realistic flat fields (waf_detected, tos_url, robots_txt_found, sitemap_urls, rss_urls, rsl_detected, ai_bot_blocks)
       - Populates ALL result fields on the job with realistic mock data matching the data shapes from the research:
         - `waf_result`: `{"waf_detected": False, "waf_type": "", "error": null}`
         - `tos_result`: `{"tos_url": "https://example.com/terms", "confidence": 0.9, "scraping_permitted": True, "permissions": [{"activity": "scraping", "permission": "explicitly_permitted", "notes": "Allowed for non-commercial use"}], "document_type": "ToS"}`
         - `robots_result`: `{"robots_found": True, "url_allowed": True, "sitemaps_from_robots": ["https://example.com/sitemap.xml"], "crawl_delay": null, "license_directives": []}`
         - `ai_bot_result`: `{"robots_found": True, "bots": {"GPTBot": {"company": "OpenAI", "blocked": True}, "ClaudeBot": {"company": "Anthropic", "blocked": False}}, "blocked_count": 1, "total_count": 2}`
         - `sitemap_result`: `{"sitemap_urls": ["https://example.com/sitemap.xml"], "source": "robots.txt", "count": 1}`
         - `rss_result`: `{"feeds": [{"url": "https://example.com/feed", "type": "application/rss+xml", "title": "Example Feed"}], "count": 1}`
         - `rsl_result`: `{"rsl_detected": False, "indicators": [], "count": 0}`
         - `metadata_result`: `{"found": True, "source": "json-ld", "score": 85, "organization": {"name": "Example Corp", "type": "Organization", "url": "https://example.com", "id": null, "logo": null, "same_as": []}}`
         - `article_result`: `{"jsonld_fields": {"@type": "NewsArticle"}, "opengraph_fields": {"og:title": "Test"}, "microdata_fields": null, "twitter_cards": {"twitter:card": "summary"}, "formats_found": ["json-ld", "opengraph", "twitter-cards"], "paywall": {"paywall_status": "free", "signals": [], "schema_accessible": True}, "profile": {"summary": "Well-structured article with JSON-LD and OpenGraph metadata.", "quality_score": 78}}`
       - Sets `job.status = "completed"` and saves
    2. POST to `/submit` with `url=https://example.com/article-test`
    3. Assert 302 redirect
    4. Follow redirect (or extract job ID from redirect URL)
    5. GET `/jobs/{job_id}` -- assert 200
    6. Refresh job from DB -- assert `job.status == "completed"`
    7. Assert all result fields are not None: `waf_result`, `tos_result`, `robots_result`, `sitemap_result`, `rss_result`, `rsl_result`, `ai_bot_result`, `metadata_result`, `article_result`

    **Test 2: `test_submit_url_deduplication_returns_existing_job`**
    Verify that submitting the same URL twice returns the existing job:
    1. Monkeypatch run_pipeline.delay as above
    2. Submit URL once -- get job_id from redirect
    3. Submit same URL again -- assert redirect points to same job_id
    4. Assert only 1 ResolutionJob exists

    **Test 3: `test_job_page_returns_404_for_nonexistent_job`**
    GET `/jobs/{random_uuid}` -- assert 404.

    **Test setup:** Use `@pytest.mark.django_db` on the class. Import from `publishers.factories`, `publishers.models`. Use `unittest.mock.MagicMock` for the monkeypatch side_effect pattern (matching test_views.py style).

    **Important:** The monkeypatch target is `"publishers.views.run_pipeline"` (the module-level import in views.py), not the function directly. Set `mock_pipeline_obj = MagicMock()` and `mock_pipeline_obj.delay.side_effect = mock_run_sync`. Then `monkeypatch.setattr("publishers.views.run_pipeline", mock_pipeline_obj)`.
  </action>
  <verify>
    Run `cd /Users/matt/src/itsascout && uv run pytest scrapegrape/publishers/tests/test_integration.py -v` -- all 3 tests pass. Also run the full test suite: `uv run pytest scrapegrape/ -v` to ensure no regressions.
  </verify>
  <done>
    Integration test file exists with 3 passing tests. Primary test proves: POST /submit -> job created -> pipeline mock runs -> all result fields populated -> GET /jobs/{id} returns 200. Full test suite passes with no regressions.
  </done>
</task>

</tasks>

<verification>
1. `uv run pytest scrapegrape/publishers/tests/test_integration.py -v` -- all tests pass
2. `uv run pytest scrapegrape/ -v` -- full suite passes (no regressions)
3. Test coverage includes: submit flow, pipeline completion, result field population, job page retrieval, deduplication, 404 handling
</verification>

<success_criteria>
- Integration test proves full chain: URL submit -> job creation -> pipeline execution -> results populated -> job page returns 200
- All 9 result fields verified as non-null after pipeline completion
- Deduplication test confirms same URL returns existing job
- Full test suite passes with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/11-report-card-ui/11-02-SUMMARY.md`
</output>
