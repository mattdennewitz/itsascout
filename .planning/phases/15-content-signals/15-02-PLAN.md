---
phase: 15-content-signals
plan: 02
type: execute
wave: 2
depends_on: ["15-01"]
files_modified:
  - scrapegrape/publishers/pipeline/supervisor.py
autonomous: true

must_haves:
  truths:
    - "Sitemap analysis step runs in the pipeline after CC step and before publisher details"
    - "Frequency step runs after sitemap analysis step (receives its result for fallback)"
    - "Both steps emit SSE started/completed events"
    - "Both steps save results to ResolutionJob JSONFields"
    - "Publisher flat fields (has_news_sitemap, update_frequency, update_frequency_hours, update_frequency_confidence) are updated from step results"
  artifacts:
    - path: "scrapegrape/publishers/pipeline/supervisor.py"
      provides: "Supervisor wiring for sitemap analysis and frequency steps"
      contains: "run_sitemap_analysis_step"
  key_links:
    - from: "scrapegrape/publishers/pipeline/supervisor.py"
      to: "scrapegrape/publishers/pipeline/steps.py"
      via: "import run_sitemap_analysis_step, run_frequency_step"
      pattern: "run_sitemap_analysis_step|run_frequency_step"
    - from: "scrapegrape/publishers/pipeline/supervisor.py"
      to: "scrapegrape/publishers/models.py"
      via: "resolution_job.sitemap_analysis_result = ..."
      pattern: "sitemap_analysis_result|frequency_result"
---

<objective>
Wire the two new step functions (sitemap analysis and frequency estimation) into the pipeline supervisor with SSE events, save results to ResolutionJob, and update Publisher flat fields.

Purpose: Makes the step functions actually run as part of the pipeline, emitting progress events and persisting results.
Output: Updated supervisor.py with both steps integrated into the pipeline execution path.
</objective>

<execution_context>
@/Users/matt/.claude/get-shit-done/workflows/execute-plan.md
@/Users/matt/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-content-signals/15-RESEARCH.md
@.planning/phases/15-content-signals/15-01-SUMMARY.md
@scrapegrape/publishers/pipeline/supervisor.py
@scrapegrape/publishers/models.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Wire sitemap analysis and frequency steps into supervisor</name>
  <files>scrapegrape/publishers/pipeline/supervisor.py</files>
  <action>
1. Add imports at top of supervisor.py (in the existing import block from steps):
   ```python
   from publishers.pipeline.steps import (
       ...existing imports...,
       run_sitemap_analysis_step,
       run_frequency_step,
   )
   ```

2. In the main pipeline execution path (the `else` branch where publisher steps run fresh, after the CC step and before the publisher details step), add:

   ```python
   # Step: Sitemap analysis (news namespace detection)
   publish_step_event(job_id, "sitemap_analysis", "started")
   sitemap_analysis_result = run_sitemap_analysis_step(publisher)
   resolution_job.sitemap_analysis_result = sitemap_analysis_result
   resolution_job.save(update_fields=["sitemap_analysis_result"])
   publish_step_event(job_id, "sitemap_analysis", "completed", sitemap_analysis_result)

   # Update publisher flat fields
   publisher.has_news_sitemap = sitemap_analysis_result.get("has_news_sitemap")
   publisher.save(update_fields=["has_news_sitemap"])

   # Step: Update frequency estimation
   publish_step_event(job_id, "frequency", "started")
   frequency_result = run_frequency_step(publisher, sitemap_analysis_result)
   resolution_job.frequency_result = frequency_result
   resolution_job.save(update_fields=["frequency_result"])
   publish_step_event(job_id, "frequency", "completed", frequency_result)

   # Update publisher flat fields
   publisher.update_frequency = frequency_result.get("frequency_label", "")
   publisher.update_frequency_hours = frequency_result.get("frequency_hours")
   publisher.update_frequency_confidence = frequency_result.get("confidence", "")
   publisher.save(update_fields=["update_frequency", "update_frequency_hours", "update_frequency_confidence"])
   ```

3. Position: After the CC step block (lines ~267-278 in current supervisor.py) and before the publisher details step. The sitemap analysis must come first because frequency step uses its lastmod_dates as fallback.

Note: Do NOT add TTL skip path handling for these steps. That is Phase 17's responsibility. The fresh execution path is all that's needed now.
  </action>
  <verify>
    `uv run python -c "from publishers.pipeline.supervisor import run_pipeline; print('OK')"` prints OK (no import errors).
    Grep supervisor.py for "sitemap_analysis" and "frequency" to confirm both steps are wired.
  </verify>
  <done>
    Both step functions are wired into the supervisor pipeline. Sitemap analysis runs after CC, frequency runs after sitemap analysis, both before publisher details. SSE events emitted. Results saved to ResolutionJob JSONFields. Publisher flat fields updated.
  </done>
</task>

</tasks>

<verification>
1. `uv run python -c "from publishers.pipeline.supervisor import run_pipeline; print('OK')"` -- no import errors
2. supervisor.py contains publish_step_event calls for "sitemap_analysis" and "frequency" steps
3. resolution_job.sitemap_analysis_result and resolution_job.frequency_result are saved
4. publisher.has_news_sitemap, publisher.update_frequency, publisher.update_frequency_hours, publisher.update_frequency_confidence are updated
5. `cd /Users/matt/src/itsascout/scrapegrape && uv run pytest publishers/tests/test_pipeline.py -v` -- all tests still pass
</verification>

<success_criteria>
- Both steps execute in the pipeline after CC and before publisher details
- Sitemap analysis runs before frequency (dependency: frequency uses sitemap_analysis_result)
- SSE events published for both steps (started + completed)
- Results persisted to ResolutionJob JSONFields
- Publisher flat fields updated from step results
- All existing tests pass (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/15-content-signals/15-02-SUMMARY.md`
</output>
