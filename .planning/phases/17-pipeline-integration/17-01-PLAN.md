---
phase: 17-pipeline-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scrapegrape/publishers/pipeline/supervisor.py
  - scrapegrape/publishers/views.py
  - scrapegrape/publishers/serializers.py
autonomous: true

must_haves:
  truths:
    - "TTL skip path copies sitemap_analysis_result, frequency_result, and news_signals_result from prior completed jobs"
    - "When prior job predates sitemap_analysis or frequency steps (null results), those steps run fresh even during skip"
    - "job_show view passes sitemap_analysis_result, frequency_result, and news_signals_result to frontend"
    - "Skip events are emitted for sitemap_analysis and frequency steps during cached runs"
  artifacts:
    - path: "scrapegrape/publishers/pipeline/supervisor.py"
      provides: "TTL skip path with new field copying and predates-step special cases"
      contains: "sitemap_analysis_result"
    - path: "scrapegrape/publishers/views.py"
      provides: "Job show view with new result fields in fallback and props"
      contains: "news_signals_result"
    - path: "scrapegrape/publishers/serializers.py"
      provides: "Publisher serializer with competitive intelligence flat fields"
      contains: "has_news_sitemap"
  key_links:
    - from: "scrapegrape/publishers/pipeline/supervisor.py"
      to: "ResolutionJob model"
      via: "values() query and field copy"
      pattern: "sitemap_analysis_result.*frequency_result.*news_signals_result"
    - from: "scrapegrape/publishers/views.py"
      to: "Jobs/Show.tsx"
      via: "inertia_render props dict"
      pattern: "sitemap_analysis_result.*job\\.sitemap_analysis_result"
---

<objective>
Add the three new competitive intelligence result fields to the backend TTL skip path, view fallback, and serializer so cached pipeline runs copy and serve all new data correctly.

Purpose: Without these changes, cached (TTL-skipped) pipeline runs produce null for the new fields, and the frontend never receives the data even when it exists from prior runs.
Output: Updated supervisor.py, views.py, and serializers.py with complete field coverage.
</objective>

<execution_context>
@/Users/matt/.claude/get-shit-done/workflows/execute-plan.md
@/Users/matt/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/17-pipeline-integration/17-RESEARCH.md
@scrapegrape/publishers/pipeline/supervisor.py
@scrapegrape/publishers/views.py
@scrapegrape/publishers/serializers.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend TTL skip path in supervisor.py with new fields and predates-step special cases</name>
  <files>scrapegrape/publishers/pipeline/supervisor.py</files>
  <action>
In `run_pipeline()`, within the `should_skip_publisher_steps()` branch (the TTL skip path starting around line 91):

1. **Add to `.values()` call** (line ~105-109): Add `"sitemap_analysis_result"`, `"frequency_result"`, `"news_signals_result"` to the values query.

2. **Add to field copy block** (after line ~121): Add three new assignments:
   ```python
   resolution_job.sitemap_analysis_result = prior["sitemap_analysis_result"]
   resolution_job.frequency_result = prior["frequency_result"]
   resolution_job.news_signals_result = prior["news_signals_result"]
   ```

3. **Add to `save(update_fields=)` call** (line ~134-138): Add the three new fields to the update_fields list.

4. **Add predates-step special cases** (after the existing CC special case at lines 152-164): Follow the EXACT same pattern as CC for both `sitemap_analysis_result` and `frequency_result`:

   For sitemap_analysis:
   ```python
   if resolution_job.sitemap_analysis_result:
       publish_step_event(job_id, "sitemap_analysis", "skipped", {"reason": "fresh"})
   else:
       # Prior job predates sitemap analysis step -- run it now
       publish_step_event(job_id, "sitemap_analysis", "started")
       sa_result = run_sitemap_analysis_step(publisher)
       resolution_job.sitemap_analysis_result = sa_result
       resolution_job.save(update_fields=["sitemap_analysis_result"])
       publish_step_event(job_id, "sitemap_analysis", "completed", sa_result)
       publisher.has_news_sitemap = sa_result.get("has_news_sitemap")
       publisher.save(update_fields=["has_news_sitemap"])
   ```

   For frequency (note: frequency needs sitemap_analysis_result as input):
   ```python
   if resolution_job.frequency_result:
       publish_step_event(job_id, "frequency", "skipped", {"reason": "fresh"})
   else:
       # Prior job predates frequency step -- run it now
       publish_step_event(job_id, "frequency", "started")
       freq_result = run_frequency_step(publisher, resolution_job.sitemap_analysis_result)
       resolution_job.frequency_result = freq_result
       resolution_job.save(update_fields=["frequency_result"])
       publish_step_event(job_id, "frequency", "completed", freq_result)
       publisher.update_frequency = freq_result.get("frequency_label", "")
       publisher.update_frequency_hours = freq_result.get("frequency_hours")
       publisher.update_frequency_confidence = freq_result.get("confidence", "")
       publisher.save(update_fields=["update_frequency", "update_frequency_hours", "update_frequency_confidence"])
   ```

   Do NOT add a special case for `news_signals_result` -- the Google News step already runs unconditionally after the skip path (lines 406-428) and will always execute.

5. Place the sitemap_analysis and frequency special cases AFTER the CC special case and BEFORE the `publish_step_event(job_id, "publisher_details", "skipped", ...)` line.
  </action>
  <verify>
Run `uv run python -c "import ast; ast.parse(open('scrapegrape/publishers/pipeline/supervisor.py').read()); print('Syntax OK')"` to verify no syntax errors.
Grep for `sitemap_analysis_result` in supervisor.py -- should appear in values(), copy block, save(), and special case.
Grep for `frequency_result` in supervisor.py -- should appear in values(), copy block, save(), and special case.
  </verify>
  <done>
TTL skip path in supervisor.py copies all three new result fields from prior jobs. When prior job predates sitemap_analysis or frequency steps, those steps run fresh with SSE events and publisher flat field updates. Google News step continues to run unconditionally (no skip case needed).
  </done>
</task>

<task type="auto">
  <name>Task 2: Add new result fields to views.py fallback and props, and update serializers.py</name>
  <files>scrapegrape/publishers/views.py, scrapegrape/publishers/serializers.py</files>
  <action>
**In `views.py` `job_show` function:**

1. **Add to `result_fields` list** (line ~186-190): Add `"sitemap_analysis_result"`, `"frequency_result"`, `"news_signals_result"` to the list. The complete list should be:
   ```python
   result_fields = [
       "waf_result", "tos_result", "robots_result", "sitemap_result",
       "rss_result", "rsl_result", "ai_bot_result", "metadata_result",
       "cc_result", "sitemap_analysis_result", "frequency_result",
       "news_signals_result",
   ]
   ```

2. **Add to props dict** (after `"cc_result"` at line ~227): Add three new entries:
   ```python
   "sitemap_analysis_result": job.sitemap_analysis_result,
   "frequency_result": job.frequency_result,
   "news_signals_result": job.news_signals_result,
   ```
   Place these after `"cc_result"` and before `"article_result"`.

**In `serializers.py` `PublisherListSerializer`:**

Add the new Publisher flat fields to the `fields` tuple. After `"ai_bot_blocks"` (or at the end before the closing paren), add:
```python
"has_paywall",
"cc_in_index", "cc_page_count", "cc_last_crawl",
"has_news_sitemap", "google_news_readiness",
"update_frequency", "update_frequency_hours", "update_frequency_confidence",
```

Note: `has_paywall` and the CC fields were also missing from the serializer (added in Phase 10 and 14 respectively but never added to serializer). Include them now for completeness.
  </action>
  <verify>
Run `uv run python -c "import ast; ast.parse(open('scrapegrape/publishers/views.py').read()); print('Syntax OK')"` to verify no syntax errors.
Run `uv run python -c "import ast; ast.parse(open('scrapegrape/publishers/serializers.py').read()); print('Syntax OK')"` to verify no syntax errors.
Run `uv run python manage.py check --no-color` to verify Django is happy.
  </verify>
  <done>
views.py job_show function includes all three new result fields in both the fallback query and the props dict passed to the frontend. serializers.py includes all competitive intelligence flat fields for the publisher list API.
  </done>
</task>

</tasks>

<verification>
1. `uv run python manage.py check --no-color` passes with no errors
2. Grep confirms `sitemap_analysis_result` appears in supervisor.py values(), copy block, save(), special case, AND in views.py result_fields and props
3. Grep confirms `frequency_result` appears in supervisor.py values(), copy block, save(), special case, AND in views.py result_fields and props
4. Grep confirms `news_signals_result` appears in supervisor.py values(), copy block, save() (NO special case needed), AND in views.py result_fields and props
5. Grep confirms serializers.py includes `has_news_sitemap`, `google_news_readiness`, `update_frequency`
</verification>

<success_criteria>
All three new result fields are wired into the backend TTL skip path, view fallback, and serializer. The predates-step special case ensures publishers first analyzed before Phases 15-16 will get fresh data on next cached run.
</success_criteria>

<output>
After completion, create `.planning/phases/17-pipeline-integration/17-01-SUMMARY.md`
</output>
